{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Quantum Machine Learning Model @ TSpark 2022 Quantum+ Camp\n",
    "by Mark Song\n",
    "Futher Optimization Needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorcircuit import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import deepchem as dc\n",
    "import tensorcircuit as tc\n",
    "import time\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "visible_devices = tf.config.get_visible_devices()\n",
    "for device in visible_devices:\n",
    "    assert device.device_type != 'GPU'\n",
    "\n",
    "tc.set_dtype(\"complex128\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = tc.set_backend(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gobal Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8\n",
    "nlayers = 10\n",
    "thetas = K.zeros([n,nlayers])\n",
    "epochs = 50\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "lp = 2**n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, datasets, transformers = dc.molnet.load_tox21(featurizer='ECFP')\n",
    "train_dataset, valid_dataset, test_dataset = datasets\n",
    "\n",
    "w_col = train_dataset.w[:, 1]\n",
    "train_num = np.nonzero(w_col)\n",
    "x_train=(train_dataset.X[train_num]*2-1)/32\n",
    "y_train=train_dataset.y[train_num][:, 1]\n",
    "w_train=train_dataset.w[train_num][:, 1]\n",
    "\n",
    "w_col = valid_dataset.w[:,1]\n",
    "val_num = np.nonzero(w_col)\n",
    "x_val=(valid_dataset.X[val_num]*2-1)/32\n",
    "y_val=valid_dataset.y[val_num][:, 1]\n",
    "w_val=valid_dataset.w[val_num][:, 1]\n",
    "\n",
    "w_col = test_dataset.w[:,1]\n",
    "test_num = np.nonzero(w_col)\n",
    "x_test=(test_dataset.X[test_num]*2-1)/32\n",
    "y_test=test_dataset.y[test_num][:, 1]\n",
    "w_test=test_dataset.w[test_num][:, 1]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test, w_test))\n",
    "test_dataset = test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Quantum Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ql_l(x, param, nl):\n",
    "    c = tc.Circuit(n,inputs=x)\n",
    "    for j in range(nl):\n",
    "        for i in range(n):\n",
    "            c.rx(i, theta=param[i, j])\n",
    "        if(j%2==1):\n",
    "            for i in range(n - 1):\n",
    "                c.cnot(i, i + 1)\n",
    "        else:\n",
    "            for i in range(n - 1):\n",
    "                c.cnot(n-1-i, n-2-i)\n",
    "    return tc.array_to_tensor([float(K.real(c.expectation_ps(z=[i]))) for i in range(n)],dtype=\"float64\")\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits = False)\n",
    "ql = keras.QuantumLayer(partial(ql_l, nl=nlayers), [n,nlayers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(1024,), name=\"digits\")\n",
    "x1 = tf.keras.layers.Dense(512, activation=\"relu\")(inputs)\n",
    "x2 = tf.keras.layers.Dropout(0.6)(x1)\n",
    "x3 = tf.keras.layers.Dense(lp, activation=\"relu\")(x2)\n",
    "#x3/=K.norm(x3)\n",
    "x4 = ql(x3)\n",
    "x5 = tf.keras.layers.ReLU()(x4)\n",
    "x6 = tf.keras.layers.Dense(1, activation=\"relu\")(x5)\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x6)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.trainable\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(lr),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.AUC()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=x_train,y=y_train, epochs=epochs, validation_data=val_dataset,sample_weight=w_train,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_result = model(x_test)\n",
    "ans = 0\n",
    "for i in range(len(testing_result)):\n",
    "  if abs(testing_result[i]-y_test[i])<=0.5 :\n",
    "    ans+=1\n",
    "print(ans/len(testing_result))\n",
    "\n",
    "auc_m = tf.keras.metrics.AUC()\n",
    "auc_m.update_state(y_test, testing_result)\n",
    "print(auc_m.result().numpy())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e8f1d8c076c9bb3313eac266411f5493046fe213e43b04a760cec028c9f2f2b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tencent_tensorcircuit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
