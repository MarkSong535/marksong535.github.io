{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI Model for Quantum Computing @ TSpark 2022 Quantum+ Camp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5isL_4BtqPi2"
      },
      "source": [
        "## Install Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_t_oL-EpD8E"
      },
      "outputs": [],
      "source": [
        "!pip install --pre deepchem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ61lzy0qXBv"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dVoGB2lpqYL8"
      },
      "outputs": [],
      "source": [
        "import deepchem as dc\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Traning Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvMimJSlsBW9"
      },
      "outputs": [],
      "source": [
        "tasks, datasets, transformers = dc.molnet.load_tox21(featurizer='ECFP')\n",
        "train_dataset, valid_dataset, test_dataset = datasets\n",
        "\n",
        "wcol = train_dataset.w[:,1]\n",
        "train_num = np.nonzero(wcol)\n",
        "x_train = train_dataset.X[train_num]\n",
        "y_train = train_dataset.y[train_num][:,1]\n",
        "w_train = train_dataset.w[train_num][:,1]\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "wcol = valid_dataset.w[:,1]\n",
        "train_num = np.nonzero(wcol)\n",
        "x_val = valid_dataset.X[train_num]\n",
        "y_val = valid_dataset.y[train_num][:,1]\n",
        "w_val = valid_dataset.w[train_num][:,1]\n",
        "\n",
        "wcol = test_dataset.w[:,1]\n",
        "train_num = np.nonzero(wcol)\n",
        "x_test = test_dataset.X[train_num]\n",
        "y_test = test_dataset.y[train_num][:,1]\n",
        "w_test = test_dataset.w[train_num][:,1]\n",
        "\n",
        "print(x_val.shape)\n",
        "print(x_train.shape)\n",
        "\n",
        "train_dataset1 = tf.data.Dataset.from_tensor_slices((x_train, y_train, w_train))\n",
        "train_dataset1 = train_dataset1.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
        "\n",
        "val_dataset1 = tf.data.Dataset.from_tensor_slices((x_val, y_val, w_val))\n",
        "val_dataset1 = val_dataset1.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset1 = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_dataset1 = test_dataset1.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
        "\n",
        "inputs = keras.Input(shape=(1024,), name=\"digits\")\n",
        "x1 = keras.layers.Dense(12, activation=\"relu\")(inputs)\n",
        "x2 = keras.layers.Dropout(.2)(x1)\n",
        "x3 = keras.layers.Dense(6, activation=\"relu\")(x2)\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x3)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=[\"accuracy\",tf.keras.metrics.AUC()])\n",
        "\n",
        "model.fit(train_dataset1, epochs=50, validation_data=val_dataset1,verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NItyOw5EKy0U"
      },
      "outputs": [],
      "source": [
        "testing_result = model(x_test)\n",
        "ans = 0\n",
        "for i in range(len(testing_result)):\n",
        "  if abs(testing_result[i]-y_test[i])<=0.5 :\n",
        "    ans+=1\n",
        "print(ans/len(testing_result))\n",
        "\n",
        "auc_m = tf.keras.metrics.AUC()\n",
        "auc_m.update_state(y_test, testing_result)\n",
        "auc_m.result().numpy()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "task4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
